{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "train = datasets.MNIST(\"\", train = True, download = True,\n",
    "                       transform = transforms.Compose([transforms.ToTensor()]))\n",
    "\n",
    "test = datasets.MNIST(\"\", train = False, download = True,\n",
    "                       transform = transforms.Compose([transforms.ToTensor()]))\n",
    "\n",
    "trainset = torch.utils.data.DataLoader(train, batch_size = 10, shuffle = True)\n",
    "test = trainset = torch.utils.data.DataLoader(test, batch_size = 10, shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "28*28 =784\n",
    "Img are 28 by 28\n",
    "flatting out the matrix that are 28*28 to a single vector\n",
    "\n",
    "64 = a fully connected neural network (every layer)\n",
    "\n",
    "```\n",
    "selfe.fc1 = nn-Linera(input, output)\n",
    "```\n",
    "\n",
    "10 stands for the numbers 0 to 9\n",
    "```\n",
    "selfe.fc4 = nn-Linera(input, 10)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc1): Linear(in_features=784, out_features=64, bias=True)\n",
      "  (fc2): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (fc3): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (fc4): Linear(in_features=64, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(784, 64)\n",
    "        self.fc2 = nn.Linear(64, 64)\n",
    "        self.fc3 = nn.Linear(64, 64)\n",
    "        self.fc4 = nn.Linear(64, 10)\n",
    "        \n",
    "    # pushing forward trought the diffrent layers\n",
    "    # relu: rectified linear\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.fc4(x)            # just for passing data\n",
    "        \n",
    "        return F.log_softmax(x, dim=1) # dim=1 --> number of axis \n",
    "        \n",
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error description\n",
    "\n",
    "```Python\n",
    "---------------------------------------------------------------------------\n",
    "AttributeError                            Traceback (most recent call last)\n",
    "<ipython-input-10-eb0b7e5874c0> in <module>\n",
    "      7         self.fc4 = nn.Linear(64, 10)\n",
    "      8 \n",
    "----> 9 net = Net()\n",
    "     10 print(net)\n",
    "\n",
    "<ipython-input-10-eb0b7e5874c0> in __init__(self)\n",
    "      2     def __init__(self):\n",
    "      3         #super().__init__()\n",
    "----> 4         self.fc1 = nn.Linear(784, 64)\n",
    "      5         self.fc2 = nn.Linear(64, 64)\n",
    "      6         self.fc3 = nn.Linear(64, 64)\n",
    "\n",
    "~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py in __setattr__(self, name, value)\n",
    "    806                 if modules is None:\n",
    "    807                     raise AttributeError(\n",
    "--> 808                         \"cannot assign module before Module.__init__() call\")\n",
    "    809                 remove_from(self.__dict__, self._parameters, self._buffers, self._non_persistent_buffers_set)\n",
    "    810                 modules[name] = value\n",
    "\n",
    "AttributeError: cannot assign module before Module.__init__() call\n",
    "```\n",
    "    \n",
    "> This error is telling you that you are missing  ```super().__init__() ``` under the ```def __init__(self):```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.rand((28,28))\n",
    "X = X.view(-1 , 28*28)\n",
    "# -1 for specifing that the input are from an unknown shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = net(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.2143, -2.3323, -2.2702, -2.2474, -2.3745, -2.4007, -2.2814, -2.2074,\n",
       "         -2.3005, -2.4227]], grad_fn=<LogSoftmaxBackward>)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## losses\n",
    "a messure of how wrong is the model\n",
    "\n",
    "goal:\n",
    "- to have loss decrese\n",
    "\n",
    "## batch\n",
    "- decrease training time (it goes faster)\n",
    "- helps to generalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/havoc/anaconda3/lib/python3.7/site-packages/torch/autograd/__init__.py:132: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729138878/work/c10/cuda/CUDAFunctions.cpp:100.)\n",
      "  allow_unreachable=True)  # allow_unreachable flag\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2152, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5653, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1440, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "\n",
    "# EPOCHS: how many full pass through the data\n",
    "EPOCHS = 3 \n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    for data in trainset:\n",
    "        # data is a batch of featuresets and lables\n",
    "        X, y = data\n",
    "        net.zero_grad()\n",
    "        output = net(X.view(-1, 28*28))\n",
    "        # calculating loss\n",
    "        loss = F.nll_loss(output, y)\n",
    "        # backpropagate\n",
    "        loss.backward()\n",
    "        # adjust the weights\n",
    "        optimizer.step()\n",
    "    print(loss)\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.964\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in trainset:\n",
    "        X, y = data\n",
    "        output = net(X.view(-1, 784))\n",
    "        for idx, i in enumerate(output):\n",
    "            if torch.argmax(i) == y[idx]:\n",
    "                correct += 1\n",
    "            total += 1\n",
    "print(\"Accuracy: \", round(correct/total, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(X[3].view(28,28))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0)\n"
     ]
    }
   ],
   "source": [
    "print(torch.argmax(net(X[3].view(-1, 784))[0]))\n",
    "# -1 is a reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
